
<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office"> 
<head> 
<link  href="style.css" rel="stylesheet" type="text/css">
<style type="text/css">
.style1 {
	font-family: "Times New Roman", Times, serif;
    font-style: normal;
}
.style2 {
	font-family: "Times New Roman", Times, serif;
}
.style3 {
	font-family: Verdana;
	font-size: 9.5pt;
}
.style3_2 {
	font-family: Verdana;
	font-size: 9.5pt;
	font-weight: bold;
	color: blue;
}
.style4 {
	font-family: "Times New Roman";
}
.style5 {
	text-align: left;
}
.style6 {
	border-width: 0px;
}
    .auto-style1
    {
        width: 300px;
        margin-top: 10px;
    }
    .auto-style4
    {
        width: 464px;
    }
    .auto-style5 {
        width: 320px;
    }
    .auto-style6 {
        width: 215px;
        height: 111px;
    }
    .auto-style8 {
        width: 215px;
        height: 124px;
    }
    .auto-style9 {
        width: 215px;
        height: 99px;
    }
    .auto-style10 {
        height: 99px;
    }
    .auto-style11 {
        width: 215px;
        height: 127px;
    }
    .auto-style12 {
        height: 127px;
    }
    .auto-style13
    {
        text-align: left;
        width: 160px;
    }
    </style>
<title>Qi Shan's Homepage</title>
</head> 
<body>
<table border="0" class="tbl1">
  <tr> 
    <td colspan="4"></td>
  </tr>
  <tr valign="top"> 
    <td width="60%" height="91"><img src="single_pixel.gif" width="1" height="140"></td>
    <td width="40%" height="91" colspan="3" valign="top" align="center"> 

    &nbsp;</td>
  </tr>
  <tr> 
    <td colspan="3"  > 
  </tr>
  <tr> 
    <td valign="top" colspan="4"> 
      <table width="95%" border="0" cellspacing="10">
       <tr>
        <td width="5%" valign="top"><img src="single_pixel.gif" width="80" height="1" alt=""><br>
		<!--<p class="auto-style5"><strong>Quick Links</strong><br>
			<a  href="#publications" class="auto-style5">
			Publications</a><br/>
            <a  href="#software" class="auto-style5">Software</a><br />
            <a  href="#contact" class="auto-style5">Contact Info</a><br />
		</p>-->
	</td>
        <td width="95%"> 
        	<h2>Qi Shan</h2>
	
			<table style="width: 100%">
				<tr>
					<td class="auto-style4">
					<p class="style1" style="width: 500px">
					<font style="font-size: 9.5pt;" face="Verdana">Qi Shan graduated from the PhD program of the <a  href="http://www.cs.washington.edu">CSE</a> 
		department of University of Washington, Seattle, supervised by <a  href="http://www.cs.washington.edu/homes/curless/">Prof. Brian Curless</a> and <a  href="http://homes.cs.washington.edu/~seitz/">Prof. Steve Seitz</a>.  
					</font></p>
			<p style="width: 500px"><font style="font-size: 9.5pt;" face="Verdana">Qi Shan leads a technology group at Apple that focuses on artificial intelligence topics. This includes neural rendering, generative AI, and the optimization of large language and vision neural networks for Apple SoC. These efforts are contributing to Apple's products and platforms, including iOS, macOS, Vision Pro, and Apple Intelligence.</font></p>
	<p class="style3" style="width: 500px">
					Email: shanqitr-atmark-gmail.com </p>
	<p class="style3" style="width: 500px"><a href="https://scholar.google.com/citations?user=0FbnKXwAAAAJ&hl=en">
					Google Scholar</a></p>					
				
</td>
                    <td class="auto-style13"></td>
					<td class="style5"><a  href="figures/shanqi_icon_2.png">
					<img src="figures/shanqi_icon_2.png" height="200" class="style6" alt=""></a></td>
					</tr>
				</table>

		<h3>Publications<a id="publications"></a></h3>
    <table style="width: 92%;">
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/talaria.png" /><br /></td>
        <td><span class="style2"><em>
          <a class="style1" href="https://arxiv.org/abs/2404.03085">Talaria: Interactively Optimizing Machine Learning Models for Efficient Inference</a></em>,</span>
          <br />
          <span class="style1">Fred Hohman, Chaoqun Wang, Jinmook Lee, Jochen Görtler, Dominik Moritz, Jeffrey Bigham, Zhile Ren, Cecile Foret, Qi Shan, and Xiaoyi Zhang</span><br />
	  <span class="style4">CHI</span><span class="style1"> 2024, Best Paper Honorable Mention</strong><br />
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/stabledreamer.png" /><br /></td>
        <td><span class="style2"><em>
          <a class="style1" href="https://arxiv.org/abs/2312.02189">StableDreamer: Taming Noisy Score Distillation Sampling for Text-to-3D</a></em>,</span>
          <br />
          <span class="style1">Pengsheng Guo, Hans Hao, Adam Caccavale, Zhongzheng Ren, Edward Zhang, Qi Shan, Aditya Sankar, Alexander G. Schwing, Alex Colburn, and Fangchang Ma</span><br />
	  <span class="style1">2023</span><br />
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/unconstrainedpruning.png" /><br /></td>
        <td><span class="style2"><em>
          <a class="style1" href="https://github.com/apple/ml-upscale">UPSCALE: Unconstrained Channel Pruning</a></em>,</span>
          <br />
          <span class="style1">Alvin Wan, Hanxiang Hao, Kaushik Patnaik, Yueyang Xu, Omer Hadad, Zhile Ren, and Qi Shan</span><br />
	  <span class="style4"><a class="style1" href="https://github.com/apple/ml-upscale">[Project page with code]</a></span><br />
	  <span class="style4">ICML</span><span class="style1"> 2023</span><br />
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/2023-hyperdiffusion.png" /><br /></td>
        <td><span class="style2"><em>
          <a class="style1" href="https://ziyaerkoc.com/hyperdiffusion/">HyperDiffusion: Generating Implicit Neural Fields with Weight-Space Diffusion</a></em>,</span>
          <br />
          <span class="style1">Ziya Erkoç, Fangchang Ma, Qi Shan,  Matthias Niessner,  Angela Dai</span><br />
          <a class="style1"  href="https://arxiv.org/abs/2303.17015">arXiv:2303.17015</a><br />
	  <a class="style1"  href="https://ziyaerkoc.com/hyperdiffusion/">Project page</a><br />
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/pointconvformer.jpg" /><br /></td>
        <td><span class="style2"><em>
          <a class="style1" href="https://arxiv.org/abs/2208.02879">PointConvFormer: Revenge of the Point-based Convolution</a></em>,</span>
          <br />
          <span class="style1">Wenxuan Wu, Li Fuxin, and Qi Shan</span><br />
          <a class="style1"  href="https://arxiv.org/abs/2208.02879">arXiv:2208.02879</a><br />
	  <span class="style4">CVPR</span><span class="style1"> 2023</span><br />
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/texturify.jpg" /><br /></td>
        <td><span class="style2"><em>
          <a class="style1" href="https://nihalsid.github.io/texturify/static/Texturify.pdf">Texturify: Generating Textures on 3D Shape Surfaces</a></em>,</span>
          <br />
          <span class="style1">Yawar Siddiqui, Justus Thies, Fangchang Ma,  Qi Shan,  Matthias Nießner, and Angela Dai</span><br />
          <a class="style1"  href="https://arxiv.org/abs/2204.02411">arXiv:2204.02411</a><br />
	  <a class="style1"  href="https://nihalsid.github.io/texturify/">Project page</a><br />
	  <span class="style4">ECCV</span><span class="style1"> 2022</span><br />
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" style="width: 180px" src="figures/fvor1.gif" /><br /></td>
        <td><span class="style2"><em>
          <a class="style1" href="https://arxiv.org/pdf/2205.07763.pdf">FvOR: Robust Joint Shape and Pose Optimization for Few-view Object Reconstruction
</a></em>,</span>
          <br />
          <span class="style1">Zhenpei Yang, Zhile Ren, Miguel Angel Bautista, Zaiwei Zhang, Qi Shan, and Qixing Huang</span><br />
          <a class="style1"  href="https://arxiv.org/abs/2205.07763">arXiv:2205.07763</a><br />
	  <a class="style1"  href="https://github.com/zhenpeiyang/FvOR">Project page</a><br />
	  <span class="style4">ECCV</span><span class="style1"> 2022</span><br />
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/enr2.gif" /><br /></td>
        <td><span class="style2"><em>
          <a class="style1" href="https://arxiv.org/abs/2107.05775">Fast and Explicit Neural View Synthesis</a></em>,</span>
          <br />
          <span class="style1">Pengsheng Guo, Miguel Angel Bautista, Alex Colburn, Liang Yang, Daniel Ulbricht, Joshua M. Susskind, and Qi Shan</span><br />
          <a class="style1"  href="https://arxiv.org/abs/2107.05775">arXiv:2107.05775</a><br />
	  <span class="style4">WACV</span><span class="style1"> 2022</span><br />
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/retrfuse.jpg" /><br /></td>
        <td><span class="style2"><em>
          <a class="style1" href="https://arxiv.org/abs/2104.00024">RetrievalFuse: Neural 3D Scene Reconstruction with a Database</a></em>,</span>
          <br />
          <span class="style1">Yawar Siddiqui, Justus Thies, Fangchang Ma, Qi Shan, Matthias Nießner, and Angela Dai,</span><br />
          <a class="style1"  href="https://arxiv.org/abs/2104.00024">arXiv:2104.00024</a><br />
	  <span class="style4">ICCV</span><span class="style1"> 2021</span><br />
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/mvs2d.jpg" /><br /></td>
        <td><span class="style2"><em>
          <a class="style1" href="https://arxiv.org/abs/2104.13325">MVS2D: Efficient Multi-view Stereo via Attention-Driven 2D Convolutions</a></em>,</span>
          <br />
          <span class="style1">Zhenpei Yang, Zhile Ren, Qi Shan, and Qixing Huang,</span><br />
          <a class="style1"  href="https://arxiv.org/abs/2104.13325">arXiv:2104.13325</a><br />
	  <span class="style4">CVPR</span><span class="style1"> 2022.</span><br />
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/screen_rec.jpg" /><br /></td>
        <td><span class="style2"><em>
          <a class="style1" href="https://www.xiaoyizhang.me/assets/Paper/CHI_2021_ScreenRecognition.pdf">Screen Recognition: Creating Accessibility Metadata for Mobile Applications from Pixels</a></em>,</span>
          <br />
          <span class="style1">Xiaoyi Zhang, Lilian de Greef, Amanda Swearngin, Samuel White, Kyle Murray, Lisa Yu, Qi Shan, Jeffrey Nichols, Jason Wu, Chris Fleizach, Aaron Everitt, and Jeffrey P. Bigham,</span><br />
	  <span class="style4">CHI</span><span class="style1"> 2021.</span><br />
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/enr_all_datasets.gif" /><br /></td>
        <td><span class="style2"><em>
          <a class="style1" href="https://arxiv.org/abs/2006.07630">Equivariant Neural Rendering</a></em>,</span>
          <br />
          <span class="style1">Emilien Dupont, Miguel Angel Bautista, Alex Colburn, Aditya Sankar, Carlos Guestrin, Josh Susskind, and Qi Shan,</span><br />
          <span class="style4">ICML</span><span class="style1"> 2020.</span><br />
          <a class="style1"  href="https://arxiv.org/abs/2006.07630">arXiv:2006.07630</a><br />
          <a class="style1"  href="https://github.com/apple/ml-equivariant-neural-rendering">Code and project page</a>
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/layoutnetv2.png" /><br /></td>
        <td><span class="style2"><em>
          <a class="style1" href="https://arxiv.org/abs/1910.04099">3D Manhattan Room Layout Reconstruction from a Single 360 Image: A Comparative Study of State-of-the-art Methods</a></em>,</span>
          <br />
          <span class="style1">Chuhang Zou, Jheng-Wei Su, Chi-Han Peng, Alex Colburn, Qi Shan, Peter Wonka, Hung-Kuo Chu, and Derek Hoiem,</span><br />
          <a class="style1"  href="https://arxiv.org/abs/1910.04099">arXiv:1910.04099</a><br />
          <a class="style1"  href="https://github.com/zouchuhang/LayoutNetv2">Code and pre-trained models</a>
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/layoutnet.png" /><br /></td>
        <td><span class="style2"><em>
          <a class="style1" href="https://arxiv.org/abs/1803.08999">LayoutNet: Reconstructing the 3D Room Layout from a Single RGB Image</a></em>,</span>
          <br />
          <span class="style1">Chuhang Zou, Alex Colburn, Qi Shan, and Derek Hoiem, </span><br />
          <span class="style4">CVPR</span><span class="style1"> 2018.</span><br />
          <a class="style1"  href="https://arxiv.org/abs/1803.08999">arXiv:1803.08999</a><br />
          <a class="style1"  href="https://github.com/zouchuhang/LayoutNet">Code</a>
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/ridi.png" /></td>
        <td><span class="style2"><em>
          <a class="style1"  href="https://yanhangpublic.github.io/ridi/index.html">RIDI: Robust IMU Double Integration</a></em>,</span>
        <br />
        <span class="style1">Hang Yan, Qi Shan, and Yasutaka Furukawa.</span><br />
	<a class="style1"  href="https://yanhangpublic.github.io/ridi/index.html">Project page</a><br />
        <a class="style1"  href="https://youtu.be/IroLp5VOPDE">Video</a><br />
	<a class="style1"  href="https://arxiv.org/abs/1712.09004">arXiv:1712.09004</a>
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/psfm_teaser.png" /></td>
        <td><span class="style2"><em>
          <a class="style1"  href="http://arxiv.org/abs/1612.01256">Panoramic Structure from Motion via Geometric Relationship Detection</a></em>,</span>
        <br />
        <span class="style1">Satoshi Ikehata, Ivaylo Boyadzhiev, Qi Shan, and Yasutaka Furukawa.</span><br />
        <span class="style1"><a class="style1" href="https://arxiv.org/abs/1612.01256">arXiv:1612.01256</a><br />
        <a class="style1"  href="https://youtu.be/k00-6ysyODg">Video</a>
        </span>
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/im2cad_teaser.png" /></td>
        <td><span class="style2"><em>
          <a class="style1"  href="http://arxiv.org/pdf/1608.05137v1.pdf">IM2CAD</a></em>,</span>
        <br />
        <span class="style1">Hamid Izadinia, Qi Shan, and Steven M. Seitz,</span><br />
	<span class="style4">CVPR</span><span class="style1"> 2017.</span><br />	
        <span class="style1"><a class="style1" href="https://arxiv.org/abs/1608.05137v2">arXiv:1608.05137 (August 2016)</a><br />
        <a class="style1"  href="http://homes.cs.washington.edu/~izadinia/im2cad.html">Project Page</a>
        </span>
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/3dv14_tn.png" /></td>
        <td><span class="style2"><em>
          <a class="style1"  href="http://grail.cs.washington.edu/projects/sq_ground2aerial/3dv14_ground2aerial.pdf">Accurate Geo-registration by Ground-to-Aerial Image Matching</a></em>,</span>
        <br />
        <span class="style1"><strong>Qi Shan</strong>, Changchang Wu, Brian Curless, Yasutaka Furukawa, Carlos Hernandez, and Steven M. Seitz,</span><br />
        <span class="style1"><span class="style4">
          3DV</span> 2014, oral presentation.<br />
        <a class="style1"  href="http://grail.cs.washington.edu/projects/sq_ground2aerial/">Project Page</a>
        </span>
        </td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/uncrop_tn.jpg" /></td>
        <td><span class="style2"><em>
          <a class="style1"  href="http://grail.cs.washington.edu/projects/sq_photo_uncrop/photouncrop_eccv14.pdf">Photo Uncrop</a></em>,
        <br />
          <strong>Qi Shan</strong>, Brian Curless, Yasutaka Furukawa, Carlos Hernandez, and Steven M. Seitz,</span><span class="style1"><span class="style4"><br />
            ECCV</span> 2014.
          </span><span class="style2">
            <br /><span class="style1">
              <a class="style1"  href="http://grail.cs.washington.edu/projects/sq_photo_uncrop/">Project Page</a></span><br />
          <a class="style1" href="http://blogs.seattletimes.com/brierdudley/2014/10/22/uncropping-photos-and-other-uw-tech-on-display/">A Seattle Times article</a></td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/cvpr14_contour.jpg" /></td>
        <td><span class="style2"><em>
          <a class="style1"  href="http://grail.cs.washington.edu/projects/sq_rome_g2/paper_camready.pdf">Occluding Contours for Multi-View Stereo</a></em>,
        <br />
          <strong>Qi Shan</strong>, Brian Curless, Yasutaka Furukawa, Carlos Hernandez, and Steven M. Seitz,</span><span class="style1"><span class="style4"><br />
            CVPR</span> 2014</span>.
          <br />
          <span style="font-family: Verdana;" lang="EN-US">
            <a class="style1"  href="http://grail.cs.washington.edu/projects/sq_rome_g2">Project Page</a></span><br />
          <br />
        </td>
      </tr>
      <tr>
        <td class="auto-style5">
          <img class="auto-style1" src="figures/shanqi-2013-turing-test.jpg" /></td>
        <td><span class="style2"><em>
          <a class="style1"  href="http://grail.cs.washington.edu/projects/sq_rome_g1/paper.pdf">The Visual Turing Test for Scene Reconstruction</a></em>,
        <br />
        <strong>Qi Shan</strong>, Riley Adams, Brian Curless, Yasutaka Furukawa, and Steven M. Seitz,
        </span><span class="style1">
          <span class="style4">
            <br />
            3DV</span> 2013</span>, <span class="style1">oral presentation. 
              <br /><strong>
              Best Paper Award</strong></span>.
            <br />
            <span style="font-family: Verdana;" lang="EN-US">
              <a class="style1"  href="http://grail.cs.washington.edu/projects/sq_rome_g1">Project Page</a></span><br />
        </td>
      </tr>
      <tr>
        <td class="auto-style5">
          <img class="auto-style1" src="figures/shanqi-2012-tonemapping.png" /></td>
        <td><span class="style2"><em>
          <a class="style1"  href="http://graphics.pixar.com/library/ToneMappingVideoUsingWavelets/paper.pdf">
            Tone Mapping High Dynamic Range Videos using Wavelets</a></em>,
        <br />
        <strong>Qi Shan</strong>, Mark Meyer, Tony DeRose, John Anderson,
        </span><span class="style1">
          <span class="style4">
            <br />
            Pixar Technical Memo #12-01</span>, 2012. </span>
        <br />
        <span style="font-family: Verdana;" lang="EN-US">
          <a class="style1"  href="http://graphics.pixar.com/library/ToneMappingVideoUsingWavelets/">Project Page</a></span><br />
        </td>
      </tr>
      <tr>
        <td class="auto-style6">
          <img class="auto-style1" src="figures/glass-heightfield-recon-thumb.jpg" /></td>
        <td><span class="style2"><em>
          <a class="style1"  href="http://grail.cs.washington.edu/projects/sq_glass_recon/cvpr12_refraction.pdf">Refractive Height Fields from Single and Multiple Images</a></em>,
        <br />
        <strong>Qi Shan</strong>, Sameer Agarwal, and Brian Curless,
        </span><span class="style1">
          <span class="style4">
            <br />
            CVPR</span> 2012</span>.
        <br />
        <span style="font-family: Verdana;" lang="EN-US">
          <a class="style1"  href="http://grail.cs.washington.edu/projects/sq_glass_recon/">Project Page</a></span></td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/liu-sac12.jpg" /></td>
        <td> <span class="style2">
          <a class="style1" href="">Toward a Visual Pedometer</a>,</span> <span class="style1">
            <br />
            <span class="style2">Dawei Liu, <strong>Qi Shan</strong>, and Dan Wu,<em>
            </em></span>
            <br />
            SAC 2012</span>.</td>
      </tr>
      <tr>
        <td class="auto-style8"><img class="auto-style1" src="figures/eccv10-glass.png" /></td>
        <td><span class="style2"><em><a class="style1"  href="http://grail.cs.washington.edu/projects/sq_obscure_glass/obscure_glass_eccv10.pdf">Seeing through Obscure Glass</a></em></span><span class="style2">,
          <br />
          <strong>Qi Shan</strong>, Brian Curless, and Tadayoshi Kohno,</span><span class="style1"><span class="style4"><br />
            ECCV</span> 2010</span>.<span class="style2"><font style="font-size 9.5pt;" face="Verdana">
              <br />
              <a  href="http://grail.cs.washington.edu/projects/sq_obscure_glass/spvdeconv/" class="style1">Spatially variant non-blind deconvolution executable</a><br />
            <span style="font-family: Verdana;" lang="EN-US"><a class="style1"  href="http://grail.cs.washington.edu/projects/sq_obscure_glass/">Project Page</a></span></td>
      </tr>
      <tr>
        <td class="auto-style9"><img class="auto-style1" src="figures/defocus_noise.jpg" /></td>
        <td class="auto-style10"><span class="style2"><em>
          <a class="style1"  href="http://grail.cs.washington.edu/projects/sq_defocus_denoise/defocus_denoise_cvpr10.pdf">Using Optical Defocus to Denoise</a></em></span><span class="style2">,
            <br />
            <strong>
              Qi Shan</strong>, Jiaya Jia, Sing Bing Kang, and Zenglu Qin,<em>
              </em> </span><span class="style1">
                <span class="style4">
                  <br />
                  CVPR</span> 2010</span>.<br />
              <span class="style2"><font style="font-size 9.5pt;" face="Verdana"><a  href="http://grail.cs.washington.edu/projects/sq_defocus_denoise/defocus_denoise_techreport1.pdf" class="style1">Technical report on non-blind deconvolution</a></font></span></td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/hdr.jpg" /></td>
        <td><span class="style2"><em>
          <a class="style1"  href="http://grail.cs.washington.edu/projects/sq_tonemapping/tonemapping_tvcg.pdf">Globally Optimized Linear Windowed Tone-Mapping</a></em><span class="style1">,
            <br />
            <strong>Qi Shan</strong>, Jiaya Jia, and Michael S. Brown, </span></span><span class="style1">
              <span class="style4">
                <br />
                TVCG</span> 2010.<span class="style2"><font style="font-size 9.5pt;" face="Verdana"><br />
                  <a  href="http://grail.cs.washington.edu/projects/sq_tonemapping/optimize_tone_mapping_code.zip" class="style1">Code</a><br />
                  <span style="font-family: Verdana;" lang="EN-US"><a class="style1"  href="http://grail.cs.washington.edu/projects/sq_tonemapping/">Project Page</a></span></font></span></span></font></span></td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/upsampling.jpg" /></td>
        <td><span class="style2"><em>
          <a class="style1"  href="res/upsampling_sa08.pdf">Fast Image/Video Upsampling</a></em><span class="style1">,
            <br />
            <strong>Qi Shan</strong>, Zhaorong Li, Jiaya Jia, and Chi-Keung Tang,
          </span></span><span class="style1">
            <span class="style4">
              <br />
              SIGGRAPH</span><b><span class="style2">
              </span></b><span class="style2">ASIA 2008.
                </span>
              <br />
          <span style="font-family: Verdana;" lang="EN-US"><a  href="http://www.cse.cuhk.edu.hk/~leojia/projects/upsampling/index.html" class="style1">Project Page</a></span></td>
      </tr>
      <tr>
        <td class="auto-style11"><img class="auto-style1" src="figures/boat1Blur.jpg" /></td>
        <td class="auto-style12"><span class="style2"><em>
          <a class="style1"  href="res/deblur_siggraph08.pdf">High-Quality Motion Deblurring From a Single Image</a></em><span class="style1">,
            <br />
            <strong>Qi Shan</strong>, Jiaya Jia,
            and Aseem Agarwala, </span></span><span class="style1"><span class="style4">
              <br />
              SIGGRAPH</span> 2008.<br />
            </span><span style="font-family: Verdana;" lang="EN-US"><a  href="http://www.cse.cuhk.edu.hk/~leojia/projects/motion_deblurring/index.html" class="style1">Project Page<br /><a  href="http://www.cs.washington.edu/education/courses/cse557/09au/projects/final/artifacts/chrislim/index.html" class="style1">Interactive deblur project page</a></span>
            <span style="font-family: Verdana;" lang="EN-US"><br /><a  href="http://www.youtube.com/watch?v=ctehqynU_SM" class="style1">Interactive deblur YouTube link</a></span></td>
      </tr>
      <tr>
        <td class="auto-style5"><img class="auto-style1" src="figures/rotational1.jpg" /></td>
        <td><em>
          <a class="style1"  href="res/rotation_deblur_final.pdf">Rotational Motion Deblurring of a Rigid Object from a Single
            Image</a></em><span class="style2">, </span>
        <font face="Verdana"><span lang="EN-US" class="style1"><em>
          <br />
          <font class="style1"><strong>Qi Shan</strong>,
            Wei Xiong, and Jiaya Jia, </font>
          <br />
        </em>ICCV</span></font><span class="style1">
          2007.</span></td>
      </tr>
    </table>
		<h3>
		    &nbsp;</h3>
            <h3>
		    Released Software</h3>
                <a  href="http://grail.cs.washington.edu/projects/sq_obscure_glass/spvdeconv/" class="style1">Spatially variant non-blind deconvolution</a><br />
        <a  href="http://grail.cs.washington.edu/projects/sq_tonemapping/optimize_tone_mapping_code.zip" class="style1">HDR Tone-mapping&nbsp;&nbsp; (in Matlab)</a><br />
		<a  href="http://www.cs.washington.edu/homes/shanqi/res/UpsamplingGPU_v0.2.zip" class="style1">Image Upsampling (GPU Enabled)</a><br />
		<a  href="http://www.cse.cuhk.edu.hk/~leojia/programs/upsampling/video_upsampling.htm" class="style1">Video Upsampling</a><span class="style1"><br />
		</span>
		<a  href="http://www.cse.cuhk.edu.hk/~leojia/programs/deconvolution/deconvolution.htm" class="style1">Non-Blind Deconvolution</a><span class="style1"><br />
		</span>
		<a  href="http://www.cse.cuhk.edu.hk/~leojia/programs/deblurring/deblurring.htm" class="style1">Single Image Deblur</a><br>
		</h4>

		<h3>Contact Info.<a id="contact"></a></h3>
			<p class="style3">
		Email: shanqi-atmark-cs.washington.edu</p>
		<p> &nbsp;</p>
	</td>
       </tr>
      </table>
      </td>
  </tr>
</table>
<!-- Do not remove this div -->
<div align="center">
<br>
</div>
<p>&nbsp;</p>
</body>
</html>
